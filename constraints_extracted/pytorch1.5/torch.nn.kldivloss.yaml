check_nan: true
constraints:
  reduce:
    default: None
    descp: 'Deprecated (see `reduction`). By default, the losses are averaged or summed
      over observations for each minibatch depending on `size_average`. When `reduce`
      is `False`, returns a loss per batch element instead and ignores `size_average`.
      Default: `True`'
    doc_dtype: bool, optional
    dtype:
    - torch.bool
    ndim:
    - '0'
  reduction:
    default: mean
    descp: 'Specifies the reduction to apply to the output: `''none''` | `''batchmean''`
      | `''sum''` | `''mean''`. `''none''`: no reduction will be applied. `''batchmean''`:
      the sum of the output will be divided by batchsize. `''sum''`: the output will
      be summed. `''mean''`: the output will be divided by the number of elements
      in the output. Default: `''mean''`'
    doc_dtype: string, optional
    dtype:
    - int
    - string
    enum:
    - batchmean
    - mean
    - none
    - sum
    ndim:
    - '0'
    range:
    - '[0,inf)'
  size_average:
    default: None
    descp: 'Deprecated (see `reduction`). By default, the losses are averaged over
      each loss element in the batch. Note that for some losses, there are multiple
      elements per sample. If the field `size_average` is set to `False`, the losses
      are instead summed for each minibatch. Ignored when reduce is `False`. Default:
      `True`'
    doc_dtype: bool, optional
    dtype:
    - torch.bool
    enum:
    - size_average
    ndim:
    - '0'
inputs:
  optional:
  - size_average
  - reduce
  - reduction
  required: []
layer_constructor: true
link: https://pytorch.org/docs/1.5.0/nn.html#torch.nn.KLDivLoss
package: torch
target: KLDivLoss
title: torch.nn.KLDivLoss
version: 1.5.0
