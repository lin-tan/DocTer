constraints:
  atol:
    default: 1e-05
    descp: absolute tolerance
    doc_dtype: float, optional
    dtype:
    - torch.float32
    ndim:
    - '0'
  check_sparse_nnz:
    default: 'False'
    descp: if True, gradcheck allows for SparseTensor input, and for any SparseTensor
      at input, gradcheck will perform check at nnz positions only.
    doc_dtype: bool, optional
    dtype:
    - torch.bool
    ndim:
    - '0'
    tensor_t:
    - SparseTensor
  eps:
    default: 1e-06
    descp: perturbation for finite differences
    doc_dtype: float, optional
    dtype:
    - torch.float32
    ndim:
    - '0'
  func:
    descp: a Python function that takes Tensor inputs and returns a Tensor or a tuple
      of Tensors
    doc_dtype: function
    structure:
    - tuple
    tensor_t:
    - torch.tensor
  inputs:
    descp: inputs to the function
    doc_dtype: tuple of Tensor or Tensor
    structure:
    - tuple
    tensor_t:
    - torch.tensor
  nondet_tol:
    default: '0.0'
    descp: tolerance for non-determinism. When running identical inputs through the
      differentiation, the results must either match exactly (default, 0.0) or be
      within this tolerance.
    doc_dtype: float, optional
    dtype:
    - torch.float32
    ndim:
    - '0'
  raise_exception:
    default: 'True'
    descp: indicating whether to raise an exception if the check fails. The exception
      gives more information about the exact nature of the failure. This is helpful
      when debugging gradchecks.
    doc_dtype: bool, optional
    dtype:
    - torch.bool
    ndim:
    - '0'
  rtol:
    default: '0.001'
    descp: relative tolerance
    doc_dtype: float, optional
    dtype:
    - torch.float32
    ndim:
    - '0'
inputs:
  optional:
  - eps
  - atol
  - rtol
  - raise_exception
  - check_sparse_nnz
  - nondet_tol
  required:
  - func
  - inputs
link: https://pytorch.org/docs/1.5.0/autograd.html#torch.autograd.gradcheck
package: torch
target: gradcheck
title: torch.autograd.gradcheck
version: 1.5.0
