check_nan: true
constraints:
  _weight:
    default: None
    descp: ''
  embedding_dim:
    descp: the size of each embedding vector
    doc_dtype: int
    dtype:
    - int
    range:
    - '[0,inf)'
    structure:
    - list
  include_last_offset:
    default: 'False'
    descp: 'if `True`, `offsets` has one additional element, where the last element
      is equivalent to the size of indices. This matches the CSR format. Note: this
      option is currently only supported when `mode="sum"`.'
    doc_dtype: bool, optional
    dtype:
    - int
    - torch.bool
    ndim:
    - '0'
    range:
    - '[0,inf)'
  max_norm:
    default: None
    descp: If given, each embedding vector with norm larger than `max_norm` is renormalized
      to have norm `max_norm`.
    doc_dtype: float, optional
    dtype:
    - torch.float32
  mode:
    default: mean
    descp: '`"sum"`, `"mean"` or `"max"`. Specifies the way to reduce the bag. `"sum"`
      computes the weighted sum, taking `per_sample_weights` into consideration. `"mean"`
      computes the average of the values in the bag, `"max"` computes the max value
      over each bag. Default: `"mean"`'
    doc_dtype: string, optional
    dtype:
    - string
    enum:
    - max
    - mean
    ndim:
    - '0'
  norm_type:
    default: '2.0'
    descp: The p of the p-norm to compute for the `max_norm` option. Default `2`.
    doc_dtype: float, optional
    dtype:
    - int
    - torch.bool
    - torch.float32
    ndim:
    - '0'
  num_embeddings:
    descp: size of the dictionary of embeddings
    doc_dtype: int
    dtype:
    - int
    range:
    - '[0,inf)'
    structure:
    - dict
  scale_grad_by_freq:
    default: 'False'
    descp: 'if given, this will scale gradients by the inverse of frequency of the
      words in the mini-batch. Default `False`. Note: this option is not supported
      when `mode="max"`.'
    doc_dtype: boolean, optional
    dtype:
    - torch.bool
    ndim:
    - '0'
  sparse:
    default: 'False'
    descp: 'if `True`, gradient w.r.t. `weight` matrix will be a sparse tensor. See
      Notes for more details regarding sparse gradients. Note: this option is not
      supported when `mode="max"`.'
    doc_dtype: bool, optional
    dtype:
    - torch.bool
    ndim:
    - '0'
    tensor_t:
    - torch.tensor
inputs:
  optional:
  - max_norm
  - norm_type
  - scale_grad_by_freq
  - mode
  - sparse
  - _weight
  - include_last_offset
  required:
  - num_embeddings
  - embedding_dim
layer_constructor: true
link: https://pytorch.org/docs/1.5.0/nn.html#torch.nn.EmbeddingBag
package: torch
target: EmbeddingBag
title: torch.nn.EmbeddingBag
version: 1.5.0
