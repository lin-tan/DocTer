check_nan: true
constraints:
  affine:
    default: 'True'
    descp: 'a boolean value that when set to `True`, this module has learnable affine
      parameters. Default: `True`'
    dtype:
    - torch.bool
    ndim:
    - '0'
  eps:
    default: 1e-05
    descp: 'a value added to the denominator for numerical stability. Default: 1e-5'
    dtype:
    - torch.float32
    ndim:
    - '0'
  momentum:
    default: '0.1'
    descp: 'the value used for the running_mean and running_var computation. Can be
      set to `None` for cumulative moving average (i.e. simple average). Default:
      0.1'
    dtype:
    - torch.bool
    - torch.float32
    ndim:
    - '0'
  num_features:
    descp: 'C  from an expected input of size (N, C, +) '
  process_group:
    default: None
    descp: synchronization of stats happen within each process group individually.
      Default behavior is synchronization across the whole world
  track_running_stats:
    default: 'True'
    descp: 'a boolean value that when set to `True`, this module tracks the running
      mean and variance, and when set to `False`, this module does not track such
      statistics and always uses batch statistics in both training and eval modes.
      Default: `True`'
    dtype:
    - torch.bool
    ndim:
    - '0'
inputs:
  optional:
  - eps
  - momentum
  - affine
  - track_running_stats
  - process_group
  required:
  - num_features
layer_constructor: true
link: https://pytorch.org/docs/1.5.0/nn.html#torch.nn.SyncBatchNorm
package: torch
target: SyncBatchNorm
title: torch.nn.SyncBatchNorm
version: 1.5.0
